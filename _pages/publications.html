---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if site.author.googlescholar %}
  <div class="wordwrap">You can also find my articles on <a href="{{site.author.googlescholar}}">my Google Scholar profile</a>.</div>
{% endif %}

<h2>Selected publications</h2><hr />
<!-- Manually added selected publication: Online BED -->
<div style="margin-bottom: 0.75em; margin-left: 0; position: relative;">
        <div style="display: flex; align-items: flex-start;">
          <span style="margin-right: 0.5em; margin-top: 0.1em;">1.</span>
          <div style="flex: 1;">
            <strong>Pérez-Vieites, S.</strong>, <a href="https://sahel13.github.io/" style="text-decoration: none;">Iqbal, S.</a>, <a href="https://users.aalto.fi/~ssarkka/" style="text-decoration: none;">Särkkä, S.</a>, & <a href="https://baumanndominik.github.io/" style="text-decoration: none;">Baumann, D.</a> (2025). Online Bayesian Experimental Design for Partially Observed Dynamical Systems. <i>arXiv preprint arXiv:2511.04403</i>.
            <br>
            <!-- <a href="{{ post.paperurl }}" style="text-decoration: none;">Download</a> | -->
            <a href="https://arxiv.org/abs/2511.04403" style="color: coral;">arXiv</a>
            <!-- <a href="{{ post.bibtexurl }}" style="text-decoration: none;">BibTeX</a> | -->
            <!-- <a href="{{ post.doiurl }}" style="text-decoration: none;">DOI</a> | -->
            <!-- <a href="{{ post.slidesurl }}" style="text-decoration: none;">Slides</a> | -->
            <!-- <a href="{{ post.code }}" style="color: coral;">Code</a> -->
            <br>
            <div style="margin-left: 1em;">
              <details class="abstract-toggle" style="display: inline-block;">
                <summary style="cursor: pointer;"><strong>Abstract</strong></summary>
                <div class="abstract-content arithmatex" style="margin-top: 0.5em; margin-left: 1em;">
                  Bayesian experimental design (BED) provides a principled framework for optimizing data collection, but existing approaches do not apply to crucial real-world settings such as dynamical systems with partial observability, where only noisy and incomplete observations are available. These systems are naturally modeled as state-space models (SSMs), where latent states mediate the link between parameters and data, making the likelihood---and thus information-theoretic objectives like the expected information gain (EIG)---intractable. In addition, the dynamical nature of the system requires online algorithms that update posterior distributions and select designs sequentially in a computationally efficient manner. We address these challenges by deriving new estimators of the EIG and its gradient that explicitly marginalize latent states, enabling scalable stochastic optimization in nonlinear SSMs. Our approach leverages nested particle filters (NPFs) for efficient online inference with convergence guarantees. Applications to realistic models, such as the susceptible-infected-recovered (SIR) and a moving source location task, show that our framework successfully handles both partial observability and online computation.
                </div>
              </details>
            </div>
          </div>
        </div>
</div>
<br>
<!-- Manually added selected publication: Mixture proposal ICASSP Ben Cox -->
<div style="margin-bottom: 0.75em; margin-left: 0; position: relative;">
        <div style="display: flex; align-items: flex-start;">
          <span style="margin-right: 0.5em; margin-top: 0.1em;">2.</span>
          <div style="flex: 1;">
            Cox, B., <strong>Pérez-Vieites, S.</strong>, <a href="https://sites.google.com/view/nzilberstein" style="text-decoration: none;">Zilberstein, N.</a>, <a href="https://scholar.google.es/citations?user=x02G5UoAAAAJ&hl=es&oi=ao" style="text-decoration: none;">Sevilla, M.</a>, <a href="https://segarra.rice.edu/" style="text-decoration: none;">Segarra, S.</a> , & <a href="https://victorelvira.github.io/" style="text-decoration: none;">Elvira, V.</a> (2024). End-to-end learning of Gaussian mixture proposals using differentiable particle filters and neural networks. In <i>ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</i> (pp.9701-9705). IEEE.
            <br>
            <a href="http://sarapv.github.io/files/paper/cox2024end.pdf" style="color:coral;">Download</a> |
            <!-- <a href="https://arxiv.org/abs/2511.04403" style="color: coral;">arXiv</a> | -->
            <a href="http://sarapv.github.io/files/bibtex/cox2024end.txt">BibTeX</a> |
            <a href="https://doi.org/10.1109/ICASSP48485.2024.10447783">DOI</a>
            <!-- <a href="{{ post.slidesurl }}" style="text-decoration: none;">Slides</a> | -->
            <!-- <a href="{{ post.code }}" style="color: coral;">Code</a> -->
            <br>
            <div style="margin-left: 1em;">
              <details class="abstract-toggle" style="display: inline-block;">
                <summary style="cursor: pointer;"><strong>Abstract</strong></summary>
                <div class="abstract-content arithmatex" style="margin-top: 0.5em; margin-left: 1em;">
                  We introduce a new method, named PropMixNN, that uses a neural network to learn the proposal distribution of a particle filter. The optimal proposal distribution is approximated as a multivariate Gaussian mixture, so the proposed method aims at learning the means and covariance matrices of the S components that characterise the mixture. This unsupervised method is trained to target the log-likelihood, which does not require knowledge of the hidden state. The performance of the method is assessed in a stochastic Lorenz 96 model, which presents a non-linear chaotic behaviour. The proposed method reduces estimation errors in comparison with the state-of-the-art, showing greater improvement in highly non-linear scenarios.
                </div>
              </details>
            </div>
          </div>
        </div>
</div>
<br>
<!-- Manually added selected publication: Nested Gaussian filters -->
<div style="margin-bottom: 0.75em; margin-left: 0; position: relative;">
        <div style="display: flex; align-items: flex-start;">
          <span style="margin-right: 0.5em; margin-top: 0.1em;">3.</span>
          <div style="flex: 1;">
            <strong>Pérez-Vieites, S.</strong>, & <a href="https://jmiguez.webs.tsc.uc3m.es/" style="text-decoration: none;">Míguez, J.</a> (2021). Nested Gaussian filters for recursive Bayesian inference and nonlinear tracking in state space models. <i>Signal Processing</i>, 189, 108295.
            <br>
            <!-- <a href="http://sarapv.github.io/files/paper/cox2024end.pdf" style="text-decoration: none;">Download</a> | -->
            <a href="https://arxiv.org/abs/2103.12666" style="color:coral;">arXiv</a> |
            <a href="http://sarapv.github.io/files/bibtex/perez2021nested.txt">BibTeX</a> |
            <a href="https://doi.org/10.1016/j.sigpro.2021.108295">DOI</a> |
            <!-- <a href="{{ post.slidesurl }}" style="text-decoration: none;">Slides</a> | -->
            <a href="https://github.com/sarapv/NestedGaussian" style="color: coral;">Code</a>
            <br>
            <div style="margin-left: 1em;">
              <details class="abstract-toggle" style="display: inline-block;">
                <summary style="cursor: pointer;"><strong>Abstract</strong></summary>
                <div class="abstract-content arithmatex" style="margin-top: 0.5em; margin-left: 1em;">
                  We introduce a new sequential methodology to calibrate the fixed parameters and track the stochastic dynamical variables of a state-space system. The proposed method is based on the nested hybrid filtering (NHF) framework of Pérez-Vieites et al. (2018), that combines two layers of filters, one inside the other, to compute the joint posterior probability distribution of the static parameters and the state variables. In particular, we explore the use of deterministic sampling techniques for Gaussian approximation in the first layer of the algorithm, instead of the Monte Carlo methods employed in the original procedure. The resulting scheme reduces the computational cost and so makes the algorithms potentially better-suited for high-dimensional state and parameter spaces. We describe a specific instance of the new method and then study its performance and efficiency of the resulting algorithms for a stochastic Lorenz 63 model and for a stochastic volatility model with real data.
                </div>
              </details>
            </div>
          </div>
        </div>
</div>
<br>

{% include base_path %}

<!-- New style rendering if publication categories are defined -->
{% if site.publication_category %}
  {% for category in site.publication_category  %}
    {% assign title_shown = false %}
    {% for post in site.publications reversed %}
      {% if post.category != category[0] %}
        {% continue %}
      {% endif %}
      {% unless title_shown %}
        <h2>{{ category[1].title }}</h2><hr />
        {% assign title_shown = true %}
      {% endunless %}
      {% include archive-single.html %}
    {% endfor %}
  {% endfor %}
{% else %}
  {% for post in site.publications reversed %}
    {% include archive-single.html %}
  {% endfor %}
{% endif %}


